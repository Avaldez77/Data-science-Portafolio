# üìä Statistical Learning ‚Äì General Topics Summary

## üîπ Core Themes

This portfolio explores **statistical learning as a principled framework** for understanding how models learn from data and how their behavior can be evaluated, compared, and improved. The projects emphasize a **data-driven approach**, focusing on interpretability, robustness, and generalization rather than purely predictive performance.

Key themes include model assumptions, evaluation under realistic conditions, and the relationship between theory and empirical results.

---

## üîç Exploratory Data Analysis & Learning Behavior

- Inspection of feature distributions and target structure.
- Understanding data-generating processes before modeling.
- Identification of noise, imbalance, and structural limitations.
- Exploration of how data characteristics influence model behavior.
- No reliance on black-box assumptions.

This stage establishes the foundation for reliable statistical modeling.

---

## üìà Regression & Classification Modeling

- Linear regression for continuous targets.
- Logistic regression for binary classification problems.
- Interpretation of coefficients and decision boundaries.
- Understanding probabilistic outputs and thresholds.
- Comparison between linear and non-linear decision functions.

These models serve as interpretable baselines for more complex methods.

---

## ‚öñÔ∏è Model Comparison & Evaluation

- Systematic comparison of multiple models.
- Train/test splits and cross-validation strategies.
- Selection of task-appropriate metrics:
  - MSE and R¬≤ for regression
  - Accuracy, Precision, Recall, F1-score, and AUC for classification
- Empirical evaluation of overfitting and underfitting.

Evaluation is treated as a core modeling component, not an afterthought.

---

## üß† Bias, Variance & Generalization

- Empirical illustration of the bias‚Äìvariance tradeoff.
- Effect of model complexity on generalization error.
- Impact of sample size and noise on learning stability.
- Motivation for regularization and model selection techniques.

These projects connect statistical theory directly to observed model behavior.

---

## ‚ö†Ô∏è Learning Under Class Imbalance

- Analysis of highly imbalanced classification problems.
- Demonstration of why accuracy can be misleading.
- Use of recall, F1-score, and AUC as more reliable metrics.
- Application of resampling techniques to improve minority-class detection.
- Evaluation of performance trade-offs after balancing.

This section highlights realistic challenges found in applied machine learning.

---

## üå≤ Tree-Based & Non-Linear Models

- Application of Random Forests for classification tasks.
- Learning complex, non-linear relationships from data.
- Feature-driven decision structures.
- Comparison with linear models in terms of flexibility and interpretability.

Tree-based models are analyzed as complementary tools rather than replacements.

---

## üß™ Methodological Principles

- Reproducible experiments using structured notebooks.
- Preservation of intermediate results and diagnostics.
- Clear linkage between raw data, modeling decisions, and outcomes.
- Emphasis on explainability and statistical reasoning.

---

## üéØ Practical Relevance

- Robust model evaluation in real-world settings.
- Improved decision-making through correct metric selection.
- Identification of modeling pitfalls such as overfitting and data imbalance.
- Applicability to real analytical and business problems.

---

## üìå Portfolio Philosophy

Rather than optimizing for maximum performance alone, this portfolio prioritizes **understanding model behavior**, **statistical rigor**, and **transparent evaluation**. The projects demonstrate how statistical learning principles guide reliable and interpretable machine learning practice.
