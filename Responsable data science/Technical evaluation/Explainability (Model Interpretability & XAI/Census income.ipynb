{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b29835",
   "metadata": {},
   "source": [
    "# Interpretable Modeling and Local Explanations with LIME\n",
    "\n",
    "This notebook trains an inherently interpretable model (Decision Tree) for global interpretability and a higher-performing ensemble model (Random Forest) explained locally with LIME on the **Census Income (Adult)** dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d5873c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lime\n",
    "from lime.lime_tabular import LimeTabularExplainer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f30923",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d30a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"adult_data.csv\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c6d7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7e4c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"income\"].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa0e90",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Separate features and target.\n",
    "- Encode categorical variables with `LabelEncoder`.\n",
    "- Encode the target labels.\n",
    "- Split into train/test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34ccf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = df.drop(\"income\", axis=1)\n",
    "y_raw = df[\"income\"]\n",
    "\n",
    "X = X_raw.copy()\n",
    "for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col])\n",
    "\n",
    "le_income = LabelEncoder()\n",
    "y = le_income.fit_transform(y_raw)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64435c29",
   "metadata": {},
   "source": [
    "## Global interpretability with a Decision Tree\n",
    "\n",
    "The Decision Tree is inherently interpretable. We inspect:\n",
    "- The full tree visualization.\n",
    "- Feature importance scores from the fitted model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e95d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "tree.fit(X_train, y_train)\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(\n",
    "    tree,\n",
    "    feature_names=X.columns,\n",
    "    class_names=le_income.classes_,\n",
    "    filled=True,\n",
    "    rounded=True\n",
    ")\n",
    "plt.title(\"Decision Tree\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273da38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = tree.feature_importances_\n",
    "features = X.columns\n",
    "\n",
    "feat_importance_df = (\n",
    "    pd.DataFrame({\"feature\": features, \"importance\": importances})\n",
    "    .sort_values(by=\"importance\", ascending=False)\n",
    ")\n",
    "\n",
    "feat_importance_df.head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e0336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.barh(feat_importance_df[\"feature\"], feat_importance_df[\"importance\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature Importance (Decision Tree)\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a51a1f",
   "metadata": {},
   "source": [
    "## Non-interpretable model + local explanations with LIME\n",
    "\n",
    "A Random Forest is less transparent than a single tree. We use LIME to explain individual predictions (local interpretability) for 3 training records.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3704ca72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "explainer = LimeTabularExplainer(\n",
    "    training_data=np.array(X_train),\n",
    "    feature_names=X.columns,\n",
    "    class_names=le_income.classes_,\n",
    "    mode=\"classification\"\n",
    ")\n",
    "\n",
    "# Select three training instances to explain\n",
    "instances_to_explain = X_train.iloc[[1, 2, 5]]\n",
    "instances_to_explain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6597171",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = {}\n",
    "\n",
    "for idx in instances_to_explain.index:\n",
    "    exp = explainer.explain_instance(\n",
    "        data_row=X_train.loc[idx].values,\n",
    "        predict_fn=model_rf.predict_proba,\n",
    "        num_features=10\n",
    "    )\n",
    "    explanations[idx] = exp\n",
    "    print(f\"\\nExplanation for record {idx}:\\n\")\n",
    "    # Display a table view inside the notebook\n",
    "    exp.show_in_notebook(show_table=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f15bdc",
   "metadata": {},
   "source": [
    "## Findings\n",
    "\n",
    "**Decision Tree (global view):**\n",
    "- The feature importance ranking highlights which variables the tree relies on most to split the data.\n",
    "\n",
    "**Random Forest + LIME (local view):**\n",
    "- For each explained record, LIME identifies the strongest feature conditions that push the prediction toward either `<=50K` or `>50K`.\n",
    "- In this dataset, income predictions tend to be influenced by combinations of education-related signals, capital gains/losses, relationship/marital indicators, and age.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
