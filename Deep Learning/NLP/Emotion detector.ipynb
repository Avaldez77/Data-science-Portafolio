{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbe4e64",
   "metadata": {},
   "source": [
    "# Emotion Detection in Tweets using a Fine-Tuned Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38cc3f",
   "metadata": {},
   "source": [
    "This notebook fine-tunes a pre-trained DistilBERT model to classify tweets into six basic emotions: anger, fear, joy, love, sadness, and surprise. Using the Hugging Face Transformers library, the workflow includes data loading, text tokenization, model training, evaluation on a test set, and sample predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c107f4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries\n",
    "!pip -q install torch torchvision\n",
    "!pip -q install numpy pandas\n",
    "!pip -q install transformers datasets scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25065db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from transformers import (DistilBertTokenizer, DataCollatorWithPadding,\n",
    "                          DistilBertForSequenceClassification, Trainer, TrainingArguments)\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81701d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DAIR AI emotion dataset\n",
    "dataset = load_dataset('dair-ai/emotion')\n",
    "\n",
    "# Inspect dataset and label names\n",
    "print(dataset)\n",
    "label_names = dataset['train'].features['label'].names\n",
    "print('Label names:', label_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer and prepare tokenization function\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example['text'], truncation=True)\n",
    "\n",
    "# Tokenize the dataset and rename label column to 'labels'\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True, remove_columns=['text'])\n",
    "tokenized_dataset = tokenized_dataset.rename_column('label', 'labels')\n",
    "\n",
    "# Data collator for dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fac2eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model for sequence classification with 6 labels\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=6).to(device)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=50,\n",
    ")\n",
    "\n",
    "# Create the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset['train'],\n",
    "    eval_dataset=tokenized_dataset['validation'],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model (this step may take some time)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e195ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test split of the emotion dataset\n",
    "test_dataset = tokenized_dataset['test']\n",
    "test_dataset.set_format(type='torch', columns=['input_ids','attention_mask','labels'])\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "model.eval()\n",
    "predictions, true_labels = [], []\n",
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "    predictions.extend(preds.cpu().numpy())\n",
    "    true_labels.extend(batch['labels'].cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n",
    "print(f'Test Precision (weighted): {precision:.4f}')\n",
    "print(f'Test Recall (weighted): {recall:.4f}')\n",
    "print(f'Test F1-score (weighted): {f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e572b5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate generalization on TweetEval emotion task\n",
    "other_dataset = load_dataset('cardiffnlp/tweet_eval', 'emotion')\n",
    "test_other_dataset = other_dataset['test']\n",
    "\n",
    "# Tokenize the TweetEval test set\n",
    "test_other_dataset = test_other_dataset.map(tokenize_function, batched=True)\n",
    "test_other_dataset.set_format(type='torch', columns=['input_ids','attention_mask','label'])\n",
    "\n",
    "# Map our model's six-label output to TweetEval's four labels\n",
    "labels_map = {\n",
    "    0: 3,  # sadness -> sadness\n",
    "    1: 1,  # joy -> joy\n",
    "    2: 2,  # love -> optimism\n",
    "    3: 0,  # anger -> anger\n",
    "    4: 3,  # fear -> sadness\n",
    "    5: 1   # surprise -> joy\n",
    "}\n",
    "\n",
    "# Create DataLoader for TweetEval\n",
    "tweet_dataloader = torch.utils.data.DataLoader(test_other_dataset, batch_size=8, shuffle=False, collate_fn=data_collator)\n",
    "\n",
    "model.eval()\n",
    "mapped_predictions, tweet_true_labels = [], []\n",
    "for batch in tweet_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "    logits = outputs.logits\n",
    "    preds = torch.argmax(logits, dim=1).cpu().numpy()\n",
    "    mapped_preds = [labels_map[p] for p in preds]\n",
    "    mapped_predictions.extend(mapped_preds)\n",
    "    tweet_true_labels.extend(batch['label'].cpu().numpy())\n",
    "\n",
    "# Compute evaluation metrics\n",
    "accuracy2 = accuracy_score(tweet_true_labels, mapped_predictions)\n",
    "precision2, recall2, f12, _ = precision_recall_fscore_support(tweet_true_labels, mapped_predictions, average='weighted')\n",
    "print(f\"TweetEval Accuracy: {accuracy2:.4f}\")\n",
    "print(f\"TweetEval Precision (weighted): {precision2:.4f}\")\n",
    "print(f\"TweetEval Recall (weighted): {recall2:.4f}\")\n",
    "print(f\"TweetEval F1-score (weighted): {f12:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cd67ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to predict the emotion of a given text\n",
    "def predict_emotion(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    predicted_index = int(torch.argmax(outputs.logits, dim=1).cpu().numpy())\n",
    "    return label_names[predicted_index]\n",
    "\n",
    "# Example predictions\n",
    "text_short = 'I am feeling absolutely wonderful today'\n",
    "print(f\"Text: '{text_short}' -> Predicted emotion: {predict_emotion(text_short)}\")\n",
    "\n",
    "text_long = 'I lost my job and I am very scared about what will happen next'\n",
    "print(f\"Text: '{text_long}' -> Predicted emotion: {predict_emotion(text_long)}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
