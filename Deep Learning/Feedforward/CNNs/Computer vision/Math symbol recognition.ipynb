{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Handwritten Math Symbol Recognition with a Convolutional Neural Network (PyTorch)\n\nThis notebook trains a **convolutional neural network (CNN)** to recognize **handwritten digits and basic math operators**\nfrom images. The goal is to demonstrate a clean, end-to-end workflow:\n\n- image preprocessing with `torchvision.transforms`\n- train/test split from a folder-based dataset\n- a compact **AlexNet-style** CNN adapted for **grayscale 100×100** inputs\n- training on GPU (if available)\n- evaluation with accuracy, precision, recall, and F1-score\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Setup\nIf you're running this locally and you don't have PyTorch/torchvision, install them first.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Uncomment if needed:\n# !pip -q install torch torchvision scikit-learn torchsummary\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "import os\nimport torch\nimport torch.nn as nn\n\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport matplotlib.pyplot as plt\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Dataset\nExpected structure (folder-per-class):\n\n```\ndataset_digits/\n  0/ ...\n  1/ ...\n  ...\n  add/ ...\n  sub/ ...\n  mul/ ...\n  ...\n```\nIf you have `dataset_digits.zip`, this cell extracts it (only if the folder doesn't exist).\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "path_dir = \"dataset_digits\"\n\nif not os.path.exists(path_dir) and os.path.exists(\"dataset_digits.zip\"):\n    os.system(\"unzip -q dataset_digits.zip\")\n\nprint(\"Dataset folder exists:\", os.path.exists(path_dir))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Data loading + preprocessing\nWe standardize the input pipeline with these transforms (order matters):\n\n1. **Resize** to 100×100 (fixed input size for the CNN)\n2. Convert to **grayscale** (1 channel)\n3. Convert to **tensor**\n4. **Normalize** so pixel mean ≈ 0.5 and std ≈ 0.5\n\nWe also create a train/test split from the folder dataset because no split is provided.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def load_and_split_dataset(data_dir, batch_size=128, train_split=0.8):\n    mean = [0.5]\n    std = [0.5]\n\n    transform = transforms.Compose([\n        transforms.Resize((100, 100)),\n        transforms.Grayscale(num_output_channels=1),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std),\n    ])\n\n    dataset = datasets.ImageFolder(root=data_dir, transform=transform)\n    train_size = int(train_split * len(dataset))\n    test_size = len(dataset) - train_size\n\n    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n\n    return train_loader, test_loader, transform, dataset\n\ndata_dir = \"dataset_digits\"\ntrain_loader, test_loader, transform, dataset = load_and_split_dataset(data_dir)\n\nprint(\"Classes:\", dataset.classes)\nprint(\"Num classes:\", len(dataset.classes))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## CNN model (AlexNet-style, adapted)\nWe build an AlexNet-inspired model adjusted for:\n- **grayscale** inputs (1 channel)\n- **100×100** spatial resolution\n- a final classifier with `num_classes` outputs\n\nNote: The output of the model are **logits**. We use `CrossEntropyLoss`, which applies softmax internally.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "class AlexNetModified(nn.Module):\n    def __init__(self, num_classes: int, dropout: float = 0.5) -> None:\n        super().__init__()\n\n        # Input: (N, 1, 100, 100)\n        self.features = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=9, stride=3, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n\n            nn.Conv2d(in_channels=32, out_channels=96, kernel_size=5, padding=2),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=3, stride=2),\n\n            nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(in_channels=192, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n\n            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n            nn.ReLU(inplace=True),\n        )\n\n        # For 100x100 input, the feature map ends up as (N, 128, 7, 7)\n        # Flatten size = 128 * 7 * 7 = 6272\n        fc_in = 128 * 7 * 7\n\n        self.classifier = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(fc_in, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=dropout),\n            nn.Linear(512, 512),\n            nn.ReLU(inplace=True),\n            nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        x = self.features(x)\n        x = torch.flatten(x, 1)\n        x = self.classifier(x)\n        return x\n\n# Quick sanity check\nnum_classes = len(dataset.classes)\nmodel = AlexNetModified(num_classes=num_classes)\ndummy = torch.randn(1, 1, 100, 100)\nout = model(dummy)\nout.shape\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## (Optional) Model summary\nIf you want a quick layer/shape overview, use `torchsummary`.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Uncomment to see a summary\n# !pip -q install torchsummary\n# from torchsummary import summary\n# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# summary(AlexNetModified(num_classes=num_classes).to(device), input_size=(1, 100, 100), device=str(device))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Training (GPU if available)\nWe train with:\n- `CrossEntropyLoss`\n- `Adam` optimizer (lr=1e-3)\n\nYou can increase `num_epochs` once you're happy with the pipeline.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def train_model(model, train_loader, valid_loader, criterion, optimizer, device, num_epochs=5):\n    model.to(device)\n\n    for epoch in range(num_epochs):\n        # Training\n        model.train()\n        total_train_loss = 0.0\n        for inputs, labels in train_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            total_train_loss += loss.item()\n\n        avg_train_loss = total_train_loss / max(1, len(train_loader))\n\n        # \"Validation\" (here we reuse the test loader as a held-out split)\n        model.eval()\n        total_valid_loss = 0.0\n        with torch.no_grad():\n            for inputs, labels in valid_loader:\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs)\n                loss = criterion(outputs, labels)\n                total_valid_loss += loss.item()\n\n        avg_valid_loss = total_valid_loss / max(1, len(valid_loader))\n\n        print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_valid_loss:.4f}\")\n\n    return model\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "model = AlexNetModified(num_classes=num_classes)\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\ntrained_model = train_model(model, train_loader, test_loader, criterion, optimizer, device, num_epochs=5)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Evaluation\nWe compute:\n- accuracy\n- weighted precision / recall / F1\n\nFor imbalanced data, weighted metrics are usually more informative than raw accuracy alone.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def predict_and_evaluate(model, data_loader, device):\n    model.to(device)\n    model.eval()\n\n    predictions, labels = [], []\n\n    with torch.no_grad():\n        for inputs, true_labels in data_loader:\n            inputs = inputs.to(device)\n            true_labels = true_labels.to(device)\n\n            outputs = model(inputs)\n            _, predicted = torch.max(outputs, 1)\n\n            predictions.extend(predicted.view(-1).cpu().numpy())\n            labels.extend(true_labels.view(-1).cpu().numpy())\n\n    accuracy = accuracy_score(labels, predictions)\n    precision, recall, f1, _ = precision_recall_fscore_support(\n        labels, predictions, average=\"weighted\", zero_division=0\n    )\n\n    return predictions, labels, accuracy, precision, recall, f1\n\npredictions, labels, accuracy, precision, recall, f1 = predict_and_evaluate(trained_model, test_loader, device)\n\nprint(f\"Accuracy:  {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall:    {recall:.4f}\")\nprint(f\"F1-score:  {f1:.4f}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Visualize a few predictions\nWe plot a handful of test images with their predicted and true labels.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "def show_predictions(data_loader, predictions, labels, class_names, num_images=10):\n    plt.figure(figsize=(14, 3))\n\n    batch = next(iter(data_loader))\n    inputs, _ = batch\n\n    for i in range(min(num_images, inputs.shape[0])):\n        plt.subplot(1, num_images, i + 1)\n        plt.imshow(inputs[i][0], cmap=\"gray\")  # grayscale channel\n        plt.title(f\"Pred: {class_names[predictions[i]]}\\nTrue: {class_names[labels[i]]}\", fontsize=8)\n        plt.axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()\n\nclass_names = dataset.classes\nshow_predictions(test_loader, predictions, labels, class_names, num_images=10)\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}